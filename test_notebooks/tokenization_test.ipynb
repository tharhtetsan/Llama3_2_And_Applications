{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "\"GenAI is amazaing\" => Gen , AI , is , amazaing, ! => [1,2,3,4,5] <br>\n",
    "most people use only 30-50,000 word vocabulary <br>\n",
    "But Llama model use 128,000 token vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_env\n",
    "load_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tiktoken\n",
    "from tiktoken.load import load_tiktoken_bpe\n",
    "import torch\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tokenizer_path = \"./content/tokenizer.model\"\n",
    "num_reserved_special_tokens = 256\n",
    "\n",
    "mergeable_ranks = load_tiktoken_bpe(tokenizer_path)\n",
    "\n",
    "num_base_tokens = len(mergeable_ranks)\n",
    "special_tokens = [\n",
    "    \"<|begin_of_text|>\",\n",
    "    \"<|end_of_text|>\",\n",
    "    \"<|reserved_special_token_0|>\",\n",
    "    \"<|reserved_special_token_1|>\",\n",
    "    \"<|finetune_right_pad_id|>\",\n",
    "    \"<|step_id|>\",\n",
    "    \"<|start_header_id|>\",\n",
    "    \"<|end_header_id|>\",\n",
    "    \"<|eom_id|>\",\n",
    "    \"<|eot_id|>\",\n",
    "    \"<|python_tag|>\",\n",
    "]\n",
    "reserved_tokens = [\n",
    "    f\"<|reserved_special_token_{2 + i}|>\"\n",
    "    for i in range(num_reserved_special_tokens - len(special_tokens))\n",
    "]\n",
    "special_tokens = special_tokens + reserved_tokens\n",
    "\n",
    "# source: https://github.com/meta-llama/llama-models/blob/main/models/llama3/api/tokenizer.py#L53\n",
    "tokenizer = tiktoken.Encoding(\n",
    "    name=Path(tokenizer_path).name,\n",
    "    pat_str=r\"(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+\",\n",
    "    mergeable_ranks=mergeable_ranks,\n",
    "    special_tokens={token: len(mergeable_ranks) + i for i, token in enumerate(special_tokens)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1016, 277, 473, 73542, 5960]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Thar Htet San\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thar Htet San'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([1016, 277, 473, 73542, 5960])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens.ipynb\n",
    "If you would like to view a UTF-8 view of the Tokens.model file, uncomment the following line and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat Tokens.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"hello world\"\n",
    "len(tokenizer.encode(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"hello\"\n",
    "prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "encoded_tokens = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "len(encoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Who wrote the book Charlotte's Web?\"\n",
    "prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "encoded_tokens = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "len(encoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128000 <|begin_of_text|>\n",
      "128006 <|start_header_id|>\n",
      "882 user\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "15546 Who\n",
      "6267  wrote\n",
      "279  the\n",
      "2363  book\n",
      "29473  Charlotte\n",
      "596 's\n",
      "5000  Web\n",
      "30 ?\n",
      "128009 <|eot_id|>\n",
      "128006 <|start_header_id|>\n",
      "78191 assistant\n",
      "128007 <|end_header_id|>\n",
      "198 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoded_tokens = [tokenizer.decode([token]) for token in encoded_tokens]\n",
    "for e, d in zip(encoded_tokens, decoded_tokens):\n",
    "    print(e, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from utils import html_tokens, llama31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; background-color: #ADE0FC; padding: 2px;\"><|begin_of_text|></span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\">user</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\">\\n\\n</span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">Who</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\"> wrote</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\"> the</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"> book</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\"> Charlotte</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">'s</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"> Web</span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\">?</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\"><|eot_id|></span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">assistant</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\">\\n</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html_tokens(decoded_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">Sup</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\">erc</span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\">al</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">if</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\">rag</span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">il</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">istic</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\">exp</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\">ial</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\">id</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">ocious</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Try one of you own:\n",
    "prompt = \"Supercalifragilisticexpialidocious\"\n",
    "encoded_tokens = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in encoded_tokens]\n",
    "display(HTML(html_tokens(decoded_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM reasoning vs tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 r's in the word \"strawberry\".\n"
     ]
    }
   ],
   "source": [
    "question = \"How many r's in the word strawberry?\"\n",
    "prompt = f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "response = llama31(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '<|begin_of_text|>', '<|start_header_id|>', 'user', '<|end_header_id|>', '\\n\\n', 'How', ' many', ' r', \"'s\", ' in', ' the', ' word', ' s', ' t', ' r', ' a', ' w', ' b', ' e', ' r', ' r', ' y', '?', ' ', '<|eot_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', '\\n']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">\\n</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"><|begin_of_text|></span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">user</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">\\n\\n</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">How</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\"> many</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"> r</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\">'s</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\"> in</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"> the</span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"> word</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\"> s</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"> t</span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\"> r</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\"> a</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\"> w</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"> b</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\"> e</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\"> r</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"> r</span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"> y</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">?</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"> </span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\"><|eot_id|></span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\">assistant</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\">\\n</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_tokens = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in encoded_tokens]\n",
    "print(decoded_tokens)\n",
    "display(HTML(html_tokens(decoded_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 r's in the word \"strawberry\".\n"
     ]
    }
   ],
   "source": [
    "question = \"How many r's in the word s t r a w b e r r y? \"\n",
    "prompt = f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "response = llama31(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">\\n</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"><|begin_of_text|></span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">user</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">\\n\\n</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">How</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\"> many</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"> r</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\">'s</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\"> in</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"> the</span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"> word</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\"> s</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"> t</span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\"> r</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\"> a</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\"> w</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"> b</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\"> e</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\"> r</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"> r</span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"> y</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">?</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"> </span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\"><|eot_id|></span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\">assistant</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\">\\n</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_tokens = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in encoded_tokens]\n",
    "display(HTML(html_tokens(decoded_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "encoded_tokens = []\n",
    "decoded_byte_tokens = []\n",
    "decoded_utf8_tokens = []\n",
    "\n",
    "with open(\"./content/tokenizer.model\", 'r') as file:\n",
    "  for i, line in enumerate(file):\n",
    "    k, v = line.strip().split(' ')\n",
    "    encoded_tokens.append({k: v})\n",
    "    decoded_byte_tokens.append({base64.b64decode(k): v})\n",
    "    decoded_utf8_tokens.append({base64.b64decode(k).decode('utf-8', errors=\"replace\") : v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'IQ==': '0'},\n",
       " {'Ig==': '1'},\n",
       " {'Iw==': '2'},\n",
       " {'JA==': '3'},\n",
       " {'JQ==': '4'},\n",
       " {'Jg==': '5'},\n",
       " {'Jw==': '6'},\n",
       " {'KA==': '7'},\n",
       " {'KQ==': '8'},\n",
       " {'Kg==': '9'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(encoded_tokens)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{b'!': '0'},\n",
       " {b'\"': '1'},\n",
       " {b'#': '2'},\n",
       " {b'$': '3'},\n",
       " {b'%': '4'},\n",
       " {b'&': '5'},\n",
       " {b\"'\": '6'},\n",
       " {b'(': '7'},\n",
       " {b')': '8'},\n",
       " {b'*': '9'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(decoded_byte_tokens)[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'!': '0'},\n",
       " {'\"': '1'},\n",
       " {'#': '2'},\n",
       " {'$': '3'},\n",
       " {'%': '4'},\n",
       " {'&': '5'},\n",
       " {\"'\": '6'},\n",
       " {'(': '7'},\n",
       " {')': '8'},\n",
       " {'*': '9'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(decoded_utf8_tokens)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'aA=='"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b64encode('h'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'aGVsbG8='"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b64encode('hello'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aGVsbG8= 15339\n"
     ]
    }
   ],
   "source": [
    "!grep \"aGVsbG8=\" ./content/tokenizer.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.11 is bigger than 9.9.\n"
     ]
    }
   ],
   "source": [
    "question = \"Which number is bigger, 9.11 or 9.9? \"\n",
    "prompt = f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "response = llama31(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.9 is bigger than 9.11.\n"
     ]
    }
   ],
   "source": [
    "response = llama31(prompt, 70)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number 9.11 is bigger than 9.9.\n",
      "\n",
      "To compare these numbers, you can look at the decimal part. Since 0.11 is greater than 0.09 (or 0.9 - 0.9 = 0 and 0.11 - 0.09 = 0.02), 9.11 is greater than 9.9\n"
     ]
    }
   ],
   "source": [
    "response = llama31(prompt, 405)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(198, '\\n'),\n",
       " (128000, '<|begin_of_text|>'),\n",
       " (128006, '<|start_header_id|>'),\n",
       " (882, 'user'),\n",
       " (128007, '<|end_header_id|>'),\n",
       " (271, '\\n\\n'),\n",
       " (23956, 'Which'),\n",
       " (1396, ' number'),\n",
       " (374, ' is'),\n",
       " (11493, ' bigger'),\n",
       " (11, ','),\n",
       " (220, ' '),\n",
       " (24, '9'),\n",
       " (13, '.'),\n",
       " (806, '11'),\n",
       " (477, ' or'),\n",
       " (220, ' '),\n",
       " (24, '9'),\n",
       " (13, '.'),\n",
       " (24, '9'),\n",
       " (30, '?'),\n",
       " (220, ' '),\n",
       " (128009, '<|eot_id|>'),\n",
       " (128006, '<|start_header_id|>'),\n",
       " (78191, 'assistant'),\n",
       " (128007, '<|end_header_id|>'),\n",
       " (198, '\\n')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_tokens = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in encoded_tokens]\n",
    "[x for x in zip(encoded_tokens, decoded_tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">\\n</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"><|begin_of_text|></span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">user</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">\\n\\n</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">Which</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\"> number</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"> is</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\"> bigger</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">,</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"> </span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\">9</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">.</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\">11</span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\"> or</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\"> </span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\">9</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\">.</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\">9</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">?</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"> </span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"><|eot_id|></span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\">assistant</span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">\\n</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html_tokens(decoded_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
